---
title: 'When GANs Get Convincing (and When They Don’t): The Art of Faking It till you Make it'
date: '2025-06-17'
lastmod: '2025-06-17'
tags: ['GAN', 'CNNs', 'Computer Vision', 'GenAI']
draft: false
summary: 'Ever come across reels on Instagram that show Queen Elizabeth breakdancing and wondered how they look so uncannily real? In a world where AI can create art, faces, and even deepfakes from scratch, GANs stand at the center. But how does AI really generate images that even humans can’t tell are fake?'
---

# Href autor name

# Redirect to portfolio

Generative Adversarial Networks (GANs) have emerged as a powerful framework for modeling complex, high-dimensional data distributions without relying on explicit density estimation. Their ability to generate photorealistic images, translate styles across domains, synthesize data for augmentation, and contribute to scientific discovery such as molecular design, positions GANs at the forefront of generative modeling research. These models excel in capturing intricate data structures, producing samples that often rival real-world data in fidelity and diversity.

However, the intricate dynamics of their training processes, including issues like mode collapse and instability, present ongoing challenges that require sophisticated techniques and deeper theoretical insights. As GANs continue to push boundaries in both practical applications and fundamental research, what underlying principles govern their generative capabilities, and how can we further improve their robustness and versatility across such diverse fields?

<TOCInline toc={props.toc} exclude="Introduction" />

![Image generation using GANs](/static/images/blog2/GAN.gif)

## Foundations

## GAN Training Paradigm

## Internal Mechanics of GANs

## Evaluating GANs : How do we improve them over epochs

## What GANs learn:Representation and Feature Disentanglement

## Failure Modes: When GANs Don’t Make It

## Advances to Mitigate Failures

## Conclusion
